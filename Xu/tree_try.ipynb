{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c97970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import hashlib\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error, mean_squared_error, r2_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "FILE_PATHS = [\n",
    "    \"/content/Dallas_Animal_Shelter_Data_Fiscal_Year_2023_-_2026_20251125.csv\",\n",
    "    \"/content/dogs_intake_outcome_2021_2025.xlsx\",\n",
    "]\n",
    "\n",
    "OUT_DIR = \"/content/tree_output\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TREE_RESULTS_TXT = os.path.join(OUT_DIR, \"survclass_tree_family_summary.txt\")\n",
    "RESULTS_CSV = os.path.join(OUT_DIR, \"survclass_results_all_configs.csv\")\n",
    "\n",
    "ADOPTION_ONLY = True\n",
    "SEED = 42\n",
    "\n",
    "K_LIST = [14]\n",
    "\n",
    "TOP_K_FS = 256\n",
    "TOP_N_BREEDS = 20\n",
    "\n",
    "PARALLEL_JOBS = max(1, (os.cpu_count() or 4) - 1)\n",
    "CHUNK_SIZE_FOR_PARALLEL = 200\n",
    "\n",
    "AGE_DAYS_MAP = {\"puppy\": 0.5 * 365.0, \"adult\": 5.0 * 365.0, \"senior\": 10.5 * 365.0}\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def read_any_table(path: str) -> pd.DataFrame:\n",
    "    if path.endswith(\".xlsx\"):\n",
    "        return pd.read_excel(path)\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "\n",
    "def load_and_merge_sources(paths: List[str]) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    for p in paths:\n",
    "        df = read_any_table(p)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def map_breed_use(breed: str) -> str:\n",
    "    if not isinstance(breed, str):\n",
    "        return \"unknown\"\n",
    "    s = breed.upper()\n",
    "    if \"SHEPHERD\" in s: return \"herding\"\n",
    "    if \"LABRADOR\" in s or \"RETRIEVER\" in s: return \"sporting\"\n",
    "    if \"TERRIER\" in s or \"PIT\" in s: return \"terrier\"\n",
    "    if \"HOUND\" in s: return \"hound\"\n",
    "    if \"POODLE\" in s: return \"nonsporting\"\n",
    "    if \"CHIHUAHUA\" in s or \"POMERANIAN\" in s: return \"toy\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def compute_stay_length_days(df: pd.DataFrame) -> pd.Series:\n",
    "    stay = (df[\"Outcome_Date\"] - df[\"Intake_Date\"]).dt.total_seconds() / 86400.0\n",
    "    return stay.round()\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame):\n",
    "    df = df[df[\"Animal_Type\"].astype(str).str.upper() == \"DOG\"].copy()\n",
    "    df[\"Intake_Date\"] = pd.to_datetime(df[\"Intake_Date\"], errors=\"coerce\")\n",
    "    df[\"Outcome_Date\"] = pd.to_datetime(df[\"Outcome_Date\"], errors=\"coerce\")\n",
    "    df[\"StayLength\"] = compute_stay_length_days(df)\n",
    "    df = df[df[\"StayLength\"].notna() & (df[\"StayLength\"] >= 0)]\n",
    "\n",
    "    if ADOPTION_ONLY:\n",
    "        df = df[df[\"Outcome_Type\"].astype(str).str.upper() == \"ADOPTION\"]\n",
    "\n",
    "    df[\"Breed_Use\"] = df[\"Animal_Breed\"].astype(str).apply(map_breed_use)\n",
    "    df[\"AgeGroup\"] = df.get(\"AgeGroup\", \"adult\").fillna(\"adult\").astype(str).str.lower()\n",
    "    df[\"AgeDays\"] = df[\"AgeGroup\"].map(AGE_DAYS_MAP).fillna(AGE_DAYS_MAP[\"adult\"])\n",
    "    df[\"AgeLog\"] = np.log1p(df[\"AgeDays\"])\n",
    "\n",
    "    df[\"Intake_Month\"] = df[\"Intake_Date\"].dt.month.fillna(0).astype(int)\n",
    "    df[\"Intake_Weekday\"] = df[\"Intake_Date\"].dt.weekday.fillna(0).astype(int)\n",
    "    df[\"IsWeekend\"] = (df[\"Intake_Weekday\"] >= 5).astype(int)\n",
    "\n",
    "    top_breeds = df[\"Animal_Breed\"].value_counts().index[:TOP_N_BREEDS]\n",
    "    for b in top_breeds:\n",
    "        df[f\"Breed_{b[:15]}\"] = (df[\"Animal_Breed\"] == b).astype(int)\n",
    "    df[\"Breed_Other\"] = (~df[\"Animal_Breed\"].isin(top_breeds)).astype(int)\n",
    "\n",
    "    y = pd.qcut(df[\"StayLength\"], q=3, labels=False).astype(int).to_numpy()\n",
    "\n",
    "    num_cols = [\"AgeLog\", \"Intake_Month\", \"Intake_Weekday\", \"IsWeekend\"]\n",
    "    X_num = df[num_cols].fillna(0).to_numpy()\n",
    "\n",
    "    X_cat = pd.get_dummies(df[\"Breed_Use\"], dummy_na=True).to_numpy()\n",
    "\n",
    "    X = np.concatenate([X_num, X_cat], axis=1)\n",
    "\n",
    "    if X.shape[1] > TOP_K_FS:\n",
    "        lr = LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=2000)\n",
    "        lr.fit(X, y)\n",
    "        coef = np.abs(lr.coef_).max(axis=0)\n",
    "        idx = np.argsort(-coef)[:TOP_K_FS]\n",
    "        X = X[:, idx]\n",
    "\n",
    "    return X, y, df[\"StayLength\"].to_numpy()\n",
    "\n",
    "\n",
    "def concordance_index(times, preds):\n",
    "    t = times.reshape(-1, 1)\n",
    "    p = preds.reshape(-1, 1)\n",
    "    valid = (t - t.T) != 0\n",
    "    conc = ((t - t.T > 0) & (p - p.T > 0)) | ((t - t.T < 0) & (p - p.T < 0))\n",
    "    return conc[valid].mean()\n",
    "\n",
    "\n",
    "def train_eval(estimator, Xtr, Xva, Xte, ytr, yva, yte, ttr, tva, tte):\n",
    "    estimator.fit(Xtr, ytr)\n",
    "    mean_t = np.array([ttr[ytr == i].mean() for i in range(3)])\n",
    "\n",
    "    def eval_split(X, y, t):\n",
    "        yp = estimator.predict(X)\n",
    "        pt = mean_t[yp]\n",
    "        return {\n",
    "            \"f1\": f1_score(y, yp, average=\"weighted\"),\n",
    "            \"cidx\": concordance_index(t, pt)\n",
    "        }\n",
    "\n",
    "    return eval_split(Xva, yva, tva), eval_split(Xte, yte, tte)\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(SEED)\n",
    "    df = load_and_merge_sources(FILE_PATHS)\n",
    "    X, y, t = build_features(df)\n",
    "\n",
    "    idx_tr, idx_te = train_test_split(np.arange(len(y)), test_size=0.15, stratify=y, random_state=SEED)\n",
    "    idx_tr, idx_va = train_test_split(idx_tr, test_size=0.1765, stratify=y[idx_tr], random_state=SEED)\n",
    "\n",
    "    Xtr, Xva, Xte = X[idx_tr], X[idx_va], X[idx_te]\n",
    "    ytr, yva, yte = y[idx_tr], y[idx_va], y[idx_te]\n",
    "    ttr, tva, tte = t[idx_tr], t[idx_va], t[idx_te]\n",
    "\n",
    "    models = {\n",
    "        \"DT\": DecisionTreeClassifier(max_depth=8, random_state=SEED),\n",
    "        \"RF\": RandomForestClassifier(n_estimators=300, random_state=SEED, n_jobs=-1),\n",
    "        \"ET\": ExtraTreesClassifier(n_estimators=300, random_state=SEED, n_jobs=-1),\n",
    "        \"GB\": GradientBoostingClassifier(n_estimators=300, random_state=SEED),\n",
    "    }\n",
    "\n",
    "    with open(TREE_RESULTS_TXT, \"w\") as f:\n",
    "        for name, model in models.items():\n",
    "            val_m, test_m = train_eval(model, Xtr, Xva, Xte, ytr, yva, yte, ttr, tva, tte)\n",
    "            f.write(f\"{name}\\tval_f1={val_m['f1']:.4f}\\tval_cidx={val_m['cidx']:.4f}\\t\"\n",
    "                    f\"test_f1={test_m['f1']:.4f}\\ttest_cidx={test_m['cidx']:.4f}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
